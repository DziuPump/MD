You are a large language model that is being evaluated as part of a master's thesis.

Your task is to take ONE software requirement X (functional or non-functional) and produce your OWN structured JSON output y that describes:
- your improved, more testable version of the requirement
- your generated test cases
- your self-assessed quality metrics

IMPORTANT:
- You are answering ONLY as yourself (this model).
- Do NOT simulate or invent outputs for other models.
- Do NOT return a list of multiple models.
- The JSON must describe only ONE model: you.

-------------------
PIPELINE (INTERNALLY)
-------------------

For the given requirement X:

1. DATA UNDERSTANDING
   - Read and understand X: id, title, description, type.
   - Identify whether it is functional (FR) or non-functional (NFR).
   - Extract key behaviours, constraints and quality attributes that need to be tested.

2. INFERENCE (TEST DESIGN)
   - Produce an augmented_requirement: a clearer, more specific, measurable and testable version of X.
   - Design a set of high-level system / acceptance test cases that a human tester could execute.
   - Cover:
     - main success paths,
     - alternative / error flows,
     - boundary or edge conditions (if applicable).

3. REASONING (SELF-EVALUATION)
   - Based on the test cases you generated, assign the following scores (0.0â€“1.0):
     - coverage_score: how completely your test cases cover the requirement.
     - testability_score: how easy it is to execute and verify your test cases.
     - clarity_score: how clear and unambiguous your test cases are.
     - consistency_score: how internally consistent and non-contradictory your test cases are.
     - quality_score: your overall quality assessment, combining the above.
   - Also provide:
     - generated_test_cases: integer, number of distinct test cases you produced.
     - latency_ms: rough estimated latency (milliseconds) for generating this result.
     - cost_usd: rough estimated API cost for generating this result.

   - Select at least ONE example test case and provide:
     - summary: short natural language description.
     - expected_result: what should happen if the system behaves correctly.

4. OUTPUT FORMAT
   - Return a SINGLE JSON object with the following structure:

   {
     "name": "<string, this model name>",
     "augmented_requirement": "<string>",
     "generated_test_cases": <integer>,
     "coverage_score": <float>,
     "testability_score": <float>,
     "clarity_score": <float>,
     "consistency_score": <float>,
     "quality_score": <float>,
     "latency_ms": <integer>,
     "cost_usd": <float>,
     "examples": [
       {
         "summary": "<string>",
         "expected_result": "<string>"
       }
     ]
   }

CONSTRAINTS:
- Output MUST be valid JSON only (no extra text before or after).
- Use double quotes for all keys and string values.
- Do NOT include any list of models or comparison_summary.
- Assume your own model name is known to you and fill it into "name".

-------------------
NOW PROCESS THIS X:
-------------------

X = {
  "id": "FR-250",
  "title": "Two-factor authentication for login",
  "description": "As a registered user, I want to enable two-factor authentication using a one-time code sent to my email or mobile app so that my account is more secure.",
  "type": "Functional Requirement"
}
